# 🌦️ Real-Time Weather Data Pipeline

This project builds a real-time weather data pipeline using:

- **Apache Kafka** for streaming data ingestion  
- **Apache Spark Structured Streaming** for real-time data processing  
- **PostgreSQL** for persistent storage   
- **OpenWeatherMap API** to fetch live weather data  

---

## 📁 Project Structure

weather-pipeline/
├── weather_producer.py # Kafka producer to fetch weather data from API
├── spark_weather_consumer.py # Spark consumer to process and transform data
├── docker-compose.yaml # Docker services setup ( Kafka, Spark, PostgreSQL, Redis)
├── .env # Environment variables (API keys etc.)
└── README.md # Project documentation



---

## ⚙️ Technologies Used

- Python
- Apache Kafka
- Apache Spark
- PostgreSQL
- Apache Airflow
- Docker & Docker Compose
- OpenWeatherMap API

---

## 🚀 Getting Started

### 1️⃣ Clone the repository
```bash
git clone https://github.com/your-username/weather-pipeline.git
cd weather-pipeline
2️⃣ Set up environment variables
Create a .env file:
OPENWEATHER_API_KEY=your_api_key_here
3️⃣ Start services
docker-compose up airflow-init
docker-compose up
🛠️ Features
Streams weather data every 10 seconds for 50+ cities

Real-time processing using Spark

Scheduled pipeline using Airflow DAGs

Stores data in PostgreSQL for querying

📊 Future Improvements
Add Grafana dashboard for live monitoring

Set up alerting for severe weather conditions

Add city selection from UI or config

📬 Contact
Created by [Your Name] – feel free to reach out via LinkedIn or GitHub issues.

📄 License
This project is licensed under the MIT License. See LICENSE for more information.


---

Let me know if you'd like me to tailor it with your GitHub username, actual name, or additional setup instructions!